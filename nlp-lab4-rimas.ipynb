{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk \nfrom nltk import ngrams\nfrom nltk import bigrams\nfrom nltk import trigrams \nfrom collections import Counter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-15T16:11:11.415380Z","iopub.execute_input":"2024-02-15T16:11:11.415892Z","iopub.status.idle":"2024-02-15T16:11:14.656690Z","shell.execute_reply.started":"2024-02-15T16:11:11.415832Z","shell.execute_reply":"2024-02-15T16:11:14.655468Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"tokenized_text = [['This', 'is', 'ngram','model'], \n                  ['This', 'is', 'smoothed', 'model'], \n                  ['This', 'is', 'unsmoothed', 'model'], \n                  ['This', 'is', 'ngram', 'lab']]\n\n\nngrams_all = {1:[], 2:[], 3:[], 4:[]}\nfor i in range(4):\n    for each in tokenized_text: \n        for j in ngrams(each, i+1): \n            ngrams_all[i+1].append(j); \n\n\nngrams_all \n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T16:11:14.658605Z","iopub.execute_input":"2024-02-15T16:11:14.659716Z","iopub.status.idle":"2024-02-15T16:11:14.672655Z","shell.execute_reply.started":"2024-02-15T16:11:14.659670Z","shell.execute_reply":"2024-02-15T16:11:14.671433Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"{1: [('This',),\n  ('is',),\n  ('ngram',),\n  ('model',),\n  ('This',),\n  ('is',),\n  ('smoothed',),\n  ('model',),\n  ('This',),\n  ('is',),\n  ('unsmoothed',),\n  ('model',),\n  ('This',),\n  ('is',),\n  ('ngram',),\n  ('lab',)],\n 2: [('This', 'is'),\n  ('is', 'ngram'),\n  ('ngram', 'model'),\n  ('This', 'is'),\n  ('is', 'smoothed'),\n  ('smoothed', 'model'),\n  ('This', 'is'),\n  ('is', 'unsmoothed'),\n  ('unsmoothed', 'model'),\n  ('This', 'is'),\n  ('is', 'ngram'),\n  ('ngram', 'lab')],\n 3: [('This', 'is', 'ngram'),\n  ('is', 'ngram', 'model'),\n  ('This', 'is', 'smoothed'),\n  ('is', 'smoothed', 'model'),\n  ('This', 'is', 'unsmoothed'),\n  ('is', 'unsmoothed', 'model'),\n  ('This', 'is', 'ngram'),\n  ('is', 'ngram', 'lab')],\n 4: [('This', 'is', 'ngram', 'model'),\n  ('This', 'is', 'smoothed', 'model'),\n  ('This', 'is', 'unsmoothed', 'model'),\n  ('This', 'is', 'ngram', 'lab')]}"},"metadata":{}}]},{"cell_type":"code","source":"from collections import Counter\n\ntrigram_counter = Counter() \n\nfor tokens in tokenized_text:\n  if tokens[0]=='This' and tokens[1]=='is':\n    trigram_counter[tokens[2]] += 1\n\nprint(trigram_counter.most_common(1))","metadata":{"execution":{"iopub.status.busy":"2024-02-15T16:14:08.333899Z","iopub.execute_input":"2024-02-15T16:14:08.334638Z","iopub.status.idle":"2024-02-15T16:14:08.342822Z","shell.execute_reply.started":"2024-02-15T16:14:08.334602Z","shell.execute_reply":"2024-02-15T16:14:08.341588Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[('ngram', 2)]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Task3\n\nngrams_all = {1:[], 2:[], 3:[], 4:[]}\nfor i in range(4):\n    for each in tokenized_text:\n        for j in ngrams(each, i+1):\n            ngrams_all[i+1].append(j);\n\n\nngrams_voc = {1:set([]), 2:set([]), 3:set([]), 4:set([])}\nfor i in range(4):\n    for gram in ngrams_all[i+1]:\n        if gram not in ngrams_voc[i+1]:\n            ngrams_voc[i+1].add(gram)\n\n\ntotal_ngrams = {1:-1, 2:-1, 3:-1, 4:-1}\ntotal_voc = {1:-1, 2:-1, 3:-1, 4:-1}\nfor i in range(4):\n    total_ngrams[i+1] = len(ngrams_all[i+1])\n    total_voc[i+1] = len(ngrams_voc[i+1])                       \n   \n\nngrams_prob = {1:[], 2:[], 3:[], 4:[]}\nfor i in range(4):\n    for ngram in ngrams_voc[i+1]:\n        tlist = [ngram]\n        tlist.append(ngrams_all[i+1].count(ngram))\n        ngrams_prob[i+1].append(tlist)\n    \n\n\nfor i in range(4):\n    for ngram in ngrams_prob[i+1]:\n        ngram[-1] = (ngram[-1]+1)/(total_ngrams[i+1]+total_voc[i+1])\n\nngrams_prob \n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T16:11:14.697196Z","iopub.execute_input":"2024-02-15T16:11:14.697648Z","iopub.status.idle":"2024-02-15T16:11:14.719828Z","shell.execute_reply.started":"2024-02-15T16:11:14.697608Z","shell.execute_reply":"2024-02-15T16:11:14.718363Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{1: [[('is',), 0.21739130434782608],\n  [('lab',), 0.08695652173913043],\n  [('ngram',), 0.13043478260869565],\n  [('This',), 0.21739130434782608],\n  [('model',), 0.17391304347826086],\n  [('smoothed',), 0.08695652173913043],\n  [('unsmoothed',), 0.08695652173913043]],\n 2: [[('smoothed', 'model'), 0.1],\n  [('is', 'smoothed'), 0.1],\n  [('ngram', 'model'), 0.1],\n  [('is', 'unsmoothed'), 0.1],\n  [('unsmoothed', 'model'), 0.1],\n  [('This', 'is'), 0.25],\n  [('ngram', 'lab'), 0.1],\n  [('is', 'ngram'), 0.15]],\n 3: [[('This', 'is', 'smoothed'), 0.13333333333333333],\n  [('is', 'ngram', 'lab'), 0.13333333333333333],\n  [('This', 'is', 'unsmoothed'), 0.13333333333333333],\n  [('is', 'smoothed', 'model'), 0.13333333333333333],\n  [('is', 'unsmoothed', 'model'), 0.13333333333333333],\n  [('This', 'is', 'ngram'), 0.2],\n  [('is', 'ngram', 'model'), 0.13333333333333333]],\n 4: [[('This', 'is', 'smoothed', 'model'), 0.25],\n  [('This', 'is', 'unsmoothed', 'model'), 0.25],\n  [('This', 'is', 'ngram', 'lab'), 0.25],\n  [('This', 'is', 'ngram', 'model'), 0.25]]}"},"metadata":{}}]},{"cell_type":"code","source":"#Task3\nngrams_all = {1:[], 2:[], 3:[], 4:[]}\nfor i in range(4):\n    for each in tokenized_text:\n        for j in ngrams(each, i+1):\n            ngrams_all[i+1].append(j);\n\n\nngrams_voc = {1:set([]), 2:set([]), 3:set([]), 4:set([])}\nfor i in range(4):\n    for gram in ngrams_all[i+1]:\n        if gram not in ngrams_voc[i+1]:\n            ngrams_voc[i+1].add(gram)\n\n\ntotal_ngrams = {1:-1, 2:-1, 3:-1, 4:-1}\ntotal_voc = {1:-1, 2:-1, 3:-1, 4:-1}\nfor i in range(4):\n    total_ngrams[i+1] = len(ngrams_all[i+1])\n    total_voc[i+1] = len(ngrams_voc[i+1])                       \n   \n\nngrams_prob = {1:[], 2:[], 3:[], 4:[]}\nfor i in range(4):\n    for ngram in ngrams_voc[i+1]:\n        tlist = [ngram]\n        tlist.append(ngrams_all[i+1].count(ngram))\n        ngrams_prob[i+1].append(tlist)\n    \n\n\nfor i in range(4):\n    for ngram in ngrams_prob[i+1]:\n        ngram[-1] = (ngram[-1])/(total_ngrams[i+1])\nngrams_prob ","metadata":{"execution":{"iopub.status.busy":"2024-02-15T16:11:14.721866Z","iopub.execute_input":"2024-02-15T16:11:14.722431Z","iopub.status.idle":"2024-02-15T16:11:14.748215Z","shell.execute_reply.started":"2024-02-15T16:11:14.722365Z","shell.execute_reply":"2024-02-15T16:11:14.747267Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{1: [[('is',), 0.25],\n  [('lab',), 0.0625],\n  [('ngram',), 0.125],\n  [('This',), 0.25],\n  [('model',), 0.1875],\n  [('smoothed',), 0.0625],\n  [('unsmoothed',), 0.0625]],\n 2: [[('smoothed', 'model'), 0.08333333333333333],\n  [('is', 'smoothed'), 0.08333333333333333],\n  [('ngram', 'model'), 0.08333333333333333],\n  [('is', 'unsmoothed'), 0.08333333333333333],\n  [('unsmoothed', 'model'), 0.08333333333333333],\n  [('This', 'is'), 0.3333333333333333],\n  [('ngram', 'lab'), 0.08333333333333333],\n  [('is', 'ngram'), 0.16666666666666666]],\n 3: [[('This', 'is', 'smoothed'), 0.125],\n  [('is', 'ngram', 'lab'), 0.125],\n  [('This', 'is', 'unsmoothed'), 0.125],\n  [('is', 'smoothed', 'model'), 0.125],\n  [('is', 'unsmoothed', 'model'), 0.125],\n  [('This', 'is', 'ngram'), 0.25],\n  [('is', 'ngram', 'model'), 0.125]],\n 4: [[('This', 'is', 'smoothed', 'model'), 0.25],\n  [('This', 'is', 'unsmoothed', 'model'), 0.25],\n  [('This', 'is', 'ngram', 'lab'), 0.25],\n  [('This', 'is', 'ngram', 'model'), 0.25]]}"},"metadata":{}}]},{"cell_type":"code","source":"# Import the required libraries\nimport nltk \nfrom nltk import ngrams\nfrom nltk import bigrams\nfrom nltk import trigrams \n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:14:50.726896Z","iopub.execute_input":"2024-02-18T10:14:50.727173Z","iopub.status.idle":"2024-02-18T10:14:52.164896Z","shell.execute_reply.started":"2024-02-18T10:14:50.727149Z","shell.execute_reply":"2024-02-18T10:14:52.164170Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"tokenized_text = [['This', 'is', 'NLP','Lab'], \n                  ['This', 'is', 'Lab', '1'], \n                  ['This', 'is', 'NLP', 'Course'], \n                  ['This', 'is', 'AI', 'Course']]\n\n#Create unigram, bigrams, trigrams, and four grams models.\n\nngrams_all = {1:[], 2:[], 3:[], 4:[]}\nfor i in range(4):\n    for each in tokenized_text: #each=sentence\n        for j in ngrams(each, i+1): \n            ngrams_all[i+1].append(j); \n\n\nngrams_all #Print the list\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:14:54.696391Z","iopub.execute_input":"2024-02-18T10:14:54.697053Z","iopub.status.idle":"2024-02-18T10:14:54.714811Z","shell.execute_reply.started":"2024-02-18T10:14:54.697024Z","shell.execute_reply":"2024-02-18T10:14:54.714123Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"{1: [('This',),\n  ('is',),\n  ('NLP',),\n  ('Lab',),\n  ('This',),\n  ('is',),\n  ('Lab',),\n  ('1',),\n  ('This',),\n  ('is',),\n  ('NLP',),\n  ('Course',),\n  ('This',),\n  ('is',),\n  ('AI',),\n  ('Course',)],\n 2: [('This', 'is'),\n  ('is', 'NLP'),\n  ('NLP', 'Lab'),\n  ('This', 'is'),\n  ('is', 'Lab'),\n  ('Lab', '1'),\n  ('This', 'is'),\n  ('is', 'NLP'),\n  ('NLP', 'Course'),\n  ('This', 'is'),\n  ('is', 'AI'),\n  ('AI', 'Course')],\n 3: [('This', 'is', 'NLP'),\n  ('is', 'NLP', 'Lab'),\n  ('This', 'is', 'Lab'),\n  ('is', 'Lab', '1'),\n  ('This', 'is', 'NLP'),\n  ('is', 'NLP', 'Course'),\n  ('This', 'is', 'AI'),\n  ('is', 'AI', 'Course')],\n 4: [('This', 'is', 'NLP', 'Lab'),\n  ('This', 'is', 'Lab', '1'),\n  ('This', 'is', 'NLP', 'Course'),\n  ('This', 'is', 'AI', 'Course')]}"},"metadata":{}}]},{"cell_type":"code","source":"ngrams_voc = {1:set([]), 2:set([]), 3:set([]), 4:set([])}\n\nfor i in range(4):\n    for gram in ngrams_all[i+1]:\n        if gram not in ngrams_voc[i+1]:\n            ngrams_voc[i+1].add(gram)\n\nngrams_voc  #Print unique n-gram vocabulary list\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:15:09.166583Z","iopub.execute_input":"2024-02-18T10:15:09.166891Z","iopub.status.idle":"2024-02-18T10:15:09.176505Z","shell.execute_reply.started":"2024-02-18T10:15:09.166866Z","shell.execute_reply":"2024-02-18T10:15:09.175498Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{1: {('1',), ('AI',), ('Course',), ('Lab',), ('NLP',), ('This',), ('is',)},\n 2: {('AI', 'Course'),\n  ('Lab', '1'),\n  ('NLP', 'Course'),\n  ('NLP', 'Lab'),\n  ('This', 'is'),\n  ('is', 'AI'),\n  ('is', 'Lab'),\n  ('is', 'NLP')},\n 3: {('This', 'is', 'AI'),\n  ('This', 'is', 'Lab'),\n  ('This', 'is', 'NLP'),\n  ('is', 'AI', 'Course'),\n  ('is', 'Lab', '1'),\n  ('is', 'NLP', 'Course'),\n  ('is', 'NLP', 'Lab')},\n 4: {('This', 'is', 'AI', 'Course'),\n  ('This', 'is', 'Lab', '1'),\n  ('This', 'is', 'NLP', 'Course'),\n  ('This', 'is', 'NLP', 'Lab')}}"},"metadata":{}}]},{"cell_type":"code","source":"total_ngrams = {1:-1, 2:-1, 3:-1, 4:-1}\ntotal_voc = {1:-1, 2:-1, 3:-1, 4:-1}\nfor i in range(4):\n    total_ngrams[i+1] = len(ngrams_all[i+1])\n    total_voc[i+1] = len(ngrams_voc[i+1])\n\ntotal_ngrams #Print total number of n-gram of each model\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:15:32.402577Z","iopub.execute_input":"2024-02-18T10:15:32.402883Z","iopub.status.idle":"2024-02-18T10:15:32.409347Z","shell.execute_reply.started":"2024-02-18T10:15:32.402861Z","shell.execute_reply":"2024-02-18T10:15:32.408470Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{1: 16, 2: 12, 3: 8, 4: 4}"},"metadata":{}}]},{"cell_type":"code","source":"total_voc  #Print total number of unique n-gram vocabulary size","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:15:43.602696Z","iopub.execute_input":"2024-02-18T10:15:43.603035Z","iopub.status.idle":"2024-02-18T10:15:43.608291Z","shell.execute_reply.started":"2024-02-18T10:15:43.603011Z","shell.execute_reply":"2024-02-18T10:15:43.607568Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{1: 7, 2: 8, 3: 7, 4: 4}"},"metadata":{}}]},{"cell_type":"code","source":"ngrams_prob = {1:[], 2:[], 3:[], 4:[]}\nfor i in range(4):\n    for ngram in ngrams_voc[i+1]:\n        tlist = [ngram]\n        tlist.append(ngrams_all[i+1].count(ngram))\n        ngrams_prob[i+1].append(tlist)\n\nngrams_prob #Print the count of n-gram \n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:15:54.777102Z","iopub.execute_input":"2024-02-18T10:15:54.777389Z","iopub.status.idle":"2024-02-18T10:15:54.785632Z","shell.execute_reply.started":"2024-02-18T10:15:54.777368Z","shell.execute_reply":"2024-02-18T10:15:54.784858Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{1: [[('NLP',), 2],\n  [('1',), 1],\n  [('Course',), 2],\n  [('Lab',), 2],\n  [('This',), 4],\n  [('is',), 4],\n  [('AI',), 1]],\n 2: [[('AI', 'Course'), 1],\n  [('NLP', 'Lab'), 1],\n  [('is', 'AI'), 1],\n  [('NLP', 'Course'), 1],\n  [('is', 'NLP'), 2],\n  [('Lab', '1'), 1],\n  [('This', 'is'), 4],\n  [('is', 'Lab'), 1]],\n 3: [[('is', 'AI', 'Course'), 1],\n  [('is', 'NLP', 'Lab'), 1],\n  [('is', 'NLP', 'Course'), 1],\n  [('is', 'Lab', '1'), 1],\n  [('This', 'is', 'AI'), 1],\n  [('This', 'is', 'NLP'), 2],\n  [('This', 'is', 'Lab'), 1]],\n 4: [[('This', 'is', 'NLP', 'Course'), 1],\n  [('This', 'is', 'AI', 'Course'), 1],\n  [('This', 'is', 'NLP', 'Lab'), 1],\n  [('This', 'is', 'Lab', '1'), 1]]}"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(4):\n    for ngram in ngrams_prob[i+1]:\n        ngram[-1] = (ngram[-1]+1)/(total_ngrams[i+1]+total_voc[i+1])\n\nngrams_prob #Print the updated list with n-gram probability\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T10:16:10.653878Z","iopub.execute_input":"2024-02-18T10:16:10.654180Z","iopub.status.idle":"2024-02-18T10:16:10.662149Z","shell.execute_reply.started":"2024-02-18T10:16:10.654160Z","shell.execute_reply":"2024-02-18T10:16:10.661239Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{1: [[('NLP',), 0.13043478260869565],\n  [('1',), 0.08695652173913043],\n  [('Course',), 0.13043478260869565],\n  [('Lab',), 0.13043478260869565],\n  [('This',), 0.21739130434782608],\n  [('is',), 0.21739130434782608],\n  [('AI',), 0.08695652173913043]],\n 2: [[('AI', 'Course'), 0.1],\n  [('NLP', 'Lab'), 0.1],\n  [('is', 'AI'), 0.1],\n  [('NLP', 'Course'), 0.1],\n  [('is', 'NLP'), 0.15],\n  [('Lab', '1'), 0.1],\n  [('This', 'is'), 0.25],\n  [('is', 'Lab'), 0.1]],\n 3: [[('is', 'AI', 'Course'), 0.13333333333333333],\n  [('is', 'NLP', 'Lab'), 0.13333333333333333],\n  [('is', 'NLP', 'Course'), 0.13333333333333333],\n  [('is', 'Lab', '1'), 0.13333333333333333],\n  [('This', 'is', 'AI'), 0.13333333333333333],\n  [('This', 'is', 'NLP'), 0.2],\n  [('This', 'is', 'Lab'), 0.13333333333333333]],\n 4: [[('This', 'is', 'NLP', 'Course'), 0.25],\n  [('This', 'is', 'AI', 'Course'), 0.25],\n  [('This', 'is', 'NLP', 'Lab'), 0.25],\n  [('This', 'is', 'Lab', '1'), 0.25]]}"},"metadata":{}}]}]}